# # ‚õèÔ∏è Text Mining: An√°lisis de Sentimiento de Reviews de Vuelos

Este proyecto, desarrollado por **Santiago Londo√±o P√©rez** (Versi√≥n 2025), es un notebook de Jupyter (`TextMising.ipynb`) dedicado al **Procesamiento de Lenguaje Natural (NLP)**.

El objetivo principal es construir y evaluar un modelo de Machine Learning capaz de clasificar el sentimiento (positivo, negativo o neutral) de tweets dirigidos a aerol√≠neas estadounidenses.

El dataset utilizado es `Tweets.csv`, que contiene miles de tweets reales del "Twitter US Airline Sentiment".

## ü§ñ Flujo de Trabajo del Proyecto

El notebook sigue un flujo de trabajo estructurado de NLP y Machine Learning, dividido en 8 etapas clave:

### 1. Carga de Datos
* Importaci√≥n de librer√≠as (`pandas`, `numpy`, `matplotlib`, `seaborn`).
* Carga del dataset `Tweets.csv`.
* Exploraci√≥n inicial con `df.head()`, `df.info()` y `df.airline_sentiment.value_counts()`.

### 2. An√°lisis Exploratorio de Datos (EDA)
* **Distribuci√≥n de Sentimientos:** Visualizaci√≥n con `sns.countplot` para entender el balance de las clases (negativo, neutral, positivo).
* **Sentimiento por Aerol√≠nea:** An√°lisis de qu√© aerol√≠neas reciben qu√© tipo de sentimiento, usando `sns.countplot` con el par√°metro `hue`.

### 3. Preprocesamiento y Limpieza de Texto
Esta es la etapa fundamental de NLP. Se crea una funci√≥n `clean_text` que aplica las siguientes transformaciones a cada tweet:
* Elimina URLs (`http...`).
* Elimina menciones de usuario (`@usuario`).
* Elimina el s√≠mbolo de hashtag (`#`), pero conserva la palabra.
* Elimina todos los caracteres no alfab√©ticos (puntuaci√≥n, n√∫meros, etc.).
* Convierte todo el texto a **min√∫sculas**.
* Elimina **Stopwords** (palabras comunes como 'the', 'is', 'in') usando la librer√≠a `NLTK`.

### 4. Vectorizaci√≥n (Bag of Words)
* Para que el modelo entienda el texto, se convierte en n√∫meros.
* Se utiliza `CountVectorizer` de `sklearn` para crear una matriz de "Bolsa de Palabras".
* Se limita el vocabulario a las 5,000 palabras (features) m√°s frecuentes para optimizar el modelo.

### 5. Preparaci√≥n para el Modelo
* Mapeo de las etiquetas de sentimiento a n√∫meros (ej. `negative` -> 0, `neutral` -> 1, `positive` -> 2).
* Divisi√≥n de los datos en conjuntos de entrenamiento y prueba (`train_test_split`) con una proporci√≥n 80/20.

### 6. Creaci√≥n y Entrenamiento del Modelo
* Se selecciona el algoritmo **Multinomial Naive Bayes** (`MultinomialNB`), un modelo cl√°sico y muy eficaz para la clasificaci√≥n de texto.
* El modelo se entrena con los datos de `X_train` y `y_train`.

### 7. Evaluaci√≥n del Modelo
* Se realizan predicciones sobre el conjunto de prueba (`X_test`).
* Se eval√∫a el rendimiento del modelo usando:
    * **Accuracy Score:** Precisi√≥n general.
    * **Classification Report:** Detalle de Precisi√≥n (Precision), Sensibilidad (Recall) y F1-Score para cada clase.
    * **Matriz de Confusi√≥n:** Visualizaci√≥n con `sns.heatmap` para entender qu√© clases confunde el modelo (ej. predecir 'neutral' cuando era 'negativo').

### 8. Prueba del Modelo con Nuevas Frases
* Se crea una funci√≥n final `predict_sentiment` que toma un texto nuevo, aplica **todo el pipeline de limpieza y vectorizaci√≥n**, y devuelve la predicci√≥n del modelo.
* Se prueba con ejemplos como "The flight was amazing" y "The flight was delayed".

## üõ†Ô∏è Librer√≠as Utilizadas

* **An√°lisis de Datos:** `pandas`, `numpy`
* **Visualizaci√≥n:** `matplotlib`, `seaborn`
* **NLP:** `re` (Expresiones Regulares), `nltk` (para Stopwords)
* **Machine Learning (Scikit-learn):**
    * `feature_extraction.text.CountVectorizer`
    * `model_selection.train_test_split`
    * `naive_bayes.MultinomialNB`
    * `metrics` (accuracy_score, classification_report, confusion_matrix)
